# Development and Application of CWGID: the California Wildfire GeoImaging Dataset for Forest Wildfire Detection
A Proposal for SciPy's 2024 conferencie.

## Overview
This repository contains a collection of Jupyter notebooks designed to collect, curate, and augment RGB GeoTIFF Sentinel-2 Satellite Imagery of wildfire-affected areas using Google Earth Engine (GEE) and analyze it using Deep Learning Convolutional Models. For demonstration purposes, this  project uses a pre-trained VGG16 model adapted for 3-channel RGB GeoTIFF files and a pre-trained EfficientNet adapted for multi-channel (6 bands) GeoTIFF files.  The models are used to detect and classify forested areas affected by wildfires. The VGG16 model trains on images taken after a wildfire and EfficientNet combines before and after wildfire imagery under one input. The aim is to provide insights into the impacts of wildfires and identify forest wildfires accurately to improve the effectiveness of disaster management.

## Installation
To get started, clone this repository to your local machine or Jupyter environment. Ensure you have Python installed, along with the following major dependencies:

TensorFlow (or Keras)
NumPy
Rasterio
Tifffile
SciKit-Learn
Matplotlib
Pandas
GeoPandas
Shapely

## Usage
Each notebook in this repository is designed for a specific step in the wildfire analysis process, from data gathering and preparation to model training and deployment. Follow the instructions within each notebook to execute the code. Here's a brief overview of what each notebook accomplishes:

### Data Preparation and Preprocessing
wildfiresData.ipynb & wildfiresDataAfter.ipynb: Download Sentinel-2 satellite images of forested areas in California before and after wildfires.

CoordinateVerification.ipynb: Plot coordinates to verify shapefile contents.  

MaskingTests.ipynb & Masks.ipynb: Create two-dimensional labels using curated polygon data of historic wildfires to overlay on satellite images. These labels are for training Fully Convolutional Models.  

FilesBinary.ipynb: Organize and label the satellite imagery data for Convolutional Neural Network (CNN) models that use 3-Channel RGB GeoTIFF files as input. 

6ChannelDataCreation.ipynb: Organize, pair and combine the before and after data under one 6-Channel input for CNN models that use 6-Channel RGB GeoTIFF.

### Data Augmentation and Segmentation
imageMaskPairingSegmenting.ipynb: Segment GeoTIFF images and their two-dimensional labels into smaller tiles (256*256 px) for analysis and model input.  

DamageTilesAugmentation.ipynb: Augment satellite images of fire-damaged areas to enhance the dataset and address class imbalance.

### Data examples and visualization
DatasetExamples.ipynb: Visualize the dataset and its two-dimensional labels for demonstration purposes.

### Model Training and Evaluation
VGG16.ipynb: Run a simple VGG16 model on labeled 3-Channel RGB post-wildfire GeoTIFF images.

ImprovedVGG16.ipynb: Enhancements to the VGG16 model, including addressing class imbalance, implementing regularization, and adding Early Stopping.

EfficientNet6Channel.ipynb: Run an EfficientNet model for 6-channel satellite images that incorporate the Before RGB GeoTIFF Wildfire Images with the After RGB GeoTIFF Wildfire Images under one input.

### Contact Information

Valeria Martin Hern√°ndez: vm58@students.uwf.edu

### Acknowledgments

I want to extend my deepest gratitude to my PhD advisors, Dr. Kristen Venable and Dr. Derek Morgan, for their invaluable guidance, support, and mentorship throughout this project. Their expertise and insights have been instrumental in shaping both the direction and success of this work.

The VGG16 and EfficientNet model developers for their robust frameworks in image classification and segmentation tasks.
TensorFlow and Keras libraries for providing the essential tools to develop and train my AI models.
Jupyter Notebooks for offering a powerful and accessible platform for our data science experiments.

### License
This project is licensed - see the LICENSE file for details.


