{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73dd5468-f3d5-4144-92b0-ed75a8d56c40",
   "metadata": {},
   "source": [
    "## Import packages necessary to structure the data and compile the EfficientNet model for 6 channel images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1455f3a2-613f-4f1b-9233-08c3e1fffd84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a655d-d7a3-44ae-aa2f-13af4be2a8c8",
   "metadata": {},
   "source": [
    "## Create, train and test the six channel VGG\n",
    "### Define a list with all the 6-channel image paths to save computational ressources in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f295f94-7d1b-4e43-aa38-043f420378c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and save six-channel image paths\n",
    "def identify_six_channel_images(directory, output_file):\n",
    "    six_channel_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.tif'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with rasterio.open(file_path) as src:\n",
    "                        if src.count == 6:\n",
    "                            six_channel_files.append(file_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file_path}: {e}\")\n",
    "    with open(output_file, 'w') as f:\n",
    "        for path in six_channel_files:\n",
    "            f.write(\"%s\\n\" % path)\n",
    "    print(f\"Identified {len(six_channel_files)} six-channel images.\")\n",
    "\n",
    "# Pre-identify six-channel images \n",
    "identify_six_channel_images('/Volumes/HD710PRO/Fire_and_Hurricane_Images/Fire/6channel/Training', 'training_six_channel_images.txt')\n",
    "identify_six_channel_images('/Volumes/HD710PRO/Fire_and_Hurricane_Images/Fire/6channel/Validation', 'validation_six_channel_images.txt')\n",
    "identify_six_channel_images('/Volumes/HD710PRO/Fire_and_Hurricane_Images/Fire/6channel/Test', 'testing_six_channel_images.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a43bc29-e94e-432d-8118-7c44ce0363dd",
   "metadata": {},
   "source": [
    "### Create a custom data generator for 6-Channel GeoTIFF Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c29a82bd-96b1-4b4a-b164-b900d3c86ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Data Generator for Six-Channel Images\n",
    "class SixChannelGenerator(Sequence):\n",
    "    def __init__(self, file_paths, labels, batch_size=32, dim=(256, 256), n_channels=6, shuffle=True):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.file_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_paths = self.file_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_x = np.empty((len(batch_paths), *self.dim, self.n_channels), dtype=np.float32)\n",
    "        batch_y = np.array(batch_labels, dtype=np.float32)\n",
    "        \n",
    "        for i, path in enumerate(batch_paths):\n",
    "            with rasterio.open(path) as src:\n",
    "                img = src.read()[:self.n_channels, :self.dim[0], :self.dim[1]]\n",
    "                img = np.moveaxis(img, 0, -1)  # Convert from channels_first to channels_last format\n",
    "                batch_x[i,] = img / 255.0  # Normalize images\n",
    "\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            temp = list(zip(self.file_paths, self.labels))\n",
    "            np.random.shuffle(temp)\n",
    "            self.file_paths, self.labels = zip(*temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8dbba2-4ed0-4019-96d4-2f7735bfef54",
   "metadata": {},
   "source": [
    "### Define the adapted EfficientNet model for Six-Channel Input and define the function to load 6 channel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be4cc3d-cdff-4dc3-99ef-84e60a81f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Adaptation for Six-Channel Input\n",
    "def create_efficientnet_six_channel(input_shape=(256, 256, 6), dropout_rate=0.3):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    \n",
    "    # Consider initializing this layer with custom weights or explore ways to adapt pre-trained weights\n",
    "    x = Conv2D(3, (3, 3), padding='same', activation='relu')(input_tensor)\n",
    "    \n",
    "    base_model = EfficientNetB0(include_top=False, input_tensor=x, weights=None)  # No pre-trained weights\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    return model\n",
    "\n",
    "def load_preprocessed_dataset(file_list_path, percentage=0.25):\n",
    "    with open(file_list_path, 'r') as file:\n",
    "        all_files = [line.strip() for line in file.readlines()]\n",
    "\n",
    "    # Ensure proper shuffling to mix damaged and undamaged images\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(all_files)\n",
    "\n",
    "    # Select a subset after shuffling\n",
    "    subset_size = int(len(all_files) * percentage)\n",
    "    selected_files = all_files[:subset_size]\n",
    "\n",
    "    # Correct the logic to match the actual directory names\n",
    "    labels = [1 if '/Damage/' in file else 0 for file in selected_files]\n",
    "\n",
    "    damaged_count = labels.count(1)\n",
    "    undamaged_count = labels.count(0)\n",
    "    print(f\"Loaded {len(selected_files)} images: {damaged_count} damaged, {undamaged_count} undamaged.\")\n",
    "    return selected_files, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d76cd9c-6663-4f2e-ac39-664a2f4da26b",
   "metadata": {},
   "source": [
    "### Load 25% of the data, define the classes and do weight class computing for class imbalnce, initialize the data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b05ea5a4-7403-4681-87f8-41f147575cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Loaded 21231 images: 5727 damaged, 15504 undamaged.\n",
      "Loaded 2652 images: 691 damaged, 1961 undamaged.\n",
      "Loaded 2716 images: 808 damaged, 1908 undamaged.\n",
      "Distribution in training data: [15504  5727]\n",
      "Distribution in validation data: [1961  691]\n",
      "Distribution in test data: [1908  808]\n",
      "Class weights: {0: 0.6846942724458205, 1: 1.85358826610791}\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "print(\"Loading datasets...\")\n",
    "train_files, train_labels = load_preprocessed_dataset('training_six_channel_images.txt', 0.25)\n",
    "val_files, val_labels =  load_preprocessed_dataset('validation_six_channel_images.txt', 0.25)\n",
    "test_files, test_labels = load_preprocessed_dataset('testing_six_channel_images.txt', 0.25)\n",
    "#Check distribution \n",
    "print(f\"Distribution in training data: {np.bincount(train_labels)}\")\n",
    "print(f\"Distribution in validation data: {np.bincount(val_labels)}\")\n",
    "print(f\"Distribution in test data: {np.bincount(test_labels)}\")\n",
    "\n",
    "# with 1 representing 'damaged' and 0 'undamaged' in the filepath\n",
    "classes = np.unique(train_labels)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=train_labels)\n",
    "\n",
    "# Create a dictionary mapping class indices to their respective weights\n",
    "class_weights_dict = {classes[i]: weight for i, weight in enumerate(class_weights)}\n",
    "print(\"Class weights:\", class_weights_dict)\n",
    "\n",
    "\n",
    "#Initialize data generators\n",
    "train_generator = SixChannelGenerator(train_files, train_labels, batch_size=32)\n",
    "val_generator = SixChannelGenerator(val_files, val_labels, batch_size=32)\n",
    "test_generator = SixChannelGenerator(test_files, test_labels, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f599e2-2c79-4ff3-b803-7c20b5bc249c",
   "metadata": {},
   "source": [
    "### Initialize, train, compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48837934-9835-4fc5-975d-0fc0271ae12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "664/664 [==============================] - 4369s 7s/step - loss: 0.4825 - accuracy: 0.7971 - precision_1: 0.7204 - recall_1: 0.4053 - val_loss: 0.6073 - val_accuracy: 0.7843 - val_precision_1: 0.9407 - val_recall_1: 0.1838 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "664/664 [==============================] - 4357s 7s/step - loss: 0.3057 - accuracy: 0.8803 - precision_1: 0.8299 - recall_1: 0.6995 - val_loss: 0.3170 - val_accuracy: 0.8703 - val_precision_1: 0.9082 - val_recall_1: 0.5586 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "664/664 [==============================] - 4284s 6s/step - loss: 0.2655 - accuracy: 0.8979 - precision_1: 0.8599 - recall_1: 0.7424 - val_loss: 0.5522 - val_accuracy: 0.8152 - val_precision_1: 0.9718 - val_recall_1: 0.2996 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "664/664 [==============================] - ETA: 0s - loss: 0.2503 - accuracy: 0.9022 - precision_1: 0.8668 - recall_1: 0.7531\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "664/664 [==============================] - 4282s 6s/step - loss: 0.2503 - accuracy: 0.9022 - precision_1: 0.8668 - recall_1: 0.7531 - val_loss: 0.5469 - val_accuracy: 0.8179 - val_precision_1: 0.9444 - val_recall_1: 0.3198 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "664/664 [==============================] - 4284s 6s/step - loss: 0.2095 - accuracy: 0.9187 - precision_1: 0.9016 - recall_1: 0.7842 - val_loss: 0.2209 - val_accuracy: 0.9125 - val_precision_1: 0.9636 - val_recall_1: 0.6903 - lr: 2.0000e-04\n",
      "Epoch 6/20\n",
      "664/664 [==============================] - 4295s 6s/step - loss: 0.1953 - accuracy: 0.9265 - precision_1: 0.9156 - recall_1: 0.8015 - val_loss: 0.1764 - val_accuracy: 0.9310 - val_precision_1: 0.9472 - val_recall_1: 0.7786 - lr: 2.0000e-04\n",
      "Epoch 7/20\n",
      "664/664 [==============================] - 4304s 6s/step - loss: 0.1789 - accuracy: 0.9298 - precision_1: 0.9181 - recall_1: 0.8121 - val_loss: 0.1646 - val_accuracy: 0.9363 - val_precision_1: 0.9293 - val_recall_1: 0.8177 - lr: 2.0000e-04\n",
      "Epoch 8/20\n",
      "664/664 [==============================] - 4297s 6s/step - loss: 0.1665 - accuracy: 0.9346 - precision_1: 0.9260 - recall_1: 0.8235 - val_loss: 0.1628 - val_accuracy: 0.9359 - val_precision_1: 0.9320 - val_recall_1: 0.8133 - lr: 2.0000e-04\n",
      "Epoch 9/20\n",
      "664/664 [==============================] - 4307s 6s/step - loss: 0.1563 - accuracy: 0.9370 - precision_1: 0.9274 - recall_1: 0.8315 - val_loss: 0.2401 - val_accuracy: 0.9057 - val_precision_1: 0.9722 - val_recall_1: 0.6570 - lr: 2.0000e-04\n",
      "Epoch 10/20\n",
      "664/664 [==============================] - ETA: 0s - loss: 0.1454 - accuracy: 0.9424 - precision_1: 0.9387 - recall_1: 0.8416\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "664/664 [==============================] - 4302s 6s/step - loss: 0.1454 - accuracy: 0.9424 - precision_1: 0.9387 - recall_1: 0.8416 - val_loss: 0.1941 - val_accuracy: 0.9291 - val_precision_1: 0.9649 - val_recall_1: 0.7554 - lr: 2.0000e-04\n",
      "Epoch 11/20\n",
      "664/664 [==============================] - 4325s 7s/step - loss: 0.1154 - accuracy: 0.9537 - precision_1: 0.9590 - recall_1: 0.8655 - val_loss: 0.1701 - val_accuracy: 0.9333 - val_precision_1: 0.9386 - val_recall_1: 0.7959 - lr: 4.0000e-05\n",
      "Epoch 12/20\n",
      "664/664 [==============================] - ETA: 0s - loss: 0.1042 - accuracy: 0.9573 - precision_1: 0.9644 - recall_1: 0.8739\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "664/664 [==============================] - 4307s 6s/step - loss: 0.1042 - accuracy: 0.9573 - precision_1: 0.9644 - recall_1: 0.8739 - val_loss: 0.1793 - val_accuracy: 0.9363 - val_precision_1: 0.9516 - val_recall_1: 0.7959 - lr: 4.0000e-05\n",
      "Epoch 13/20\n",
      "664/664 [==============================] - 4290s 6s/step - loss: 0.1020 - accuracy: 0.9588 - precision_1: 0.9665 - recall_1: 0.8776 - val_loss: 0.1956 - val_accuracy: 0.9333 - val_precision_1: 0.9606 - val_recall_1: 0.7757 - lr: 8.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = create_efficientnet_six_channel()\n",
    "\n",
    "# Model Training with Callbacks for Optimal Training Control\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('efficientnet_6channel_best.keras', save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "# Fit the model\n",
    "model.fit(train_generator, epochs=20, validation_data=val_generator,\n",
    "          callbacks=[early_stopping, model_checkpoint, reduce_lr], verbose=1)\n",
    "\n",
    "model.save('6channelEN_25.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c2a9cf-9f92-46ab-b66a-6de4d919365a",
   "metadata": {},
   "source": [
    "### Test the model on the unseen test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "188e42b8-3da5-4cca-b332-2c6068d5f43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 118s 1s/step - loss: 0.1784 - accuracy: 0.9267 - precision_1: 0.9259 - recall_1: 0.8193\n",
      "Test Loss: 0.1784033179283142, Test Accuracy: 0.9267305135726929, Test Precision: 0.9258741140365601, Test Recall: 0.8193069100379944\n"
     ]
    }
   ],
   "source": [
    "#Test the model\n",
    "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_generator, verbose = 1)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}, Test Precision: {test_precision}, Test Recall: {test_recall}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
