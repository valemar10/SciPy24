{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d47db4f2-5044-442f-b215-94033e9ae389",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amartinh/opt/anaconda3/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52d13ed8-a7d7-44d0-af80-56d69b296d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_training_path = \"/Volumes/HD710PRO/Fire_and_Hurricane_Images/Fire/BinaryData/Training\"\n",
    "base_testing_path = \"/Volumes/HD710PRO/Fire_and_Hurricane_Images/Fire/BinaryData/Test\"\n",
    "\n",
    "#custom image generator\n",
    "def custom_image_generator(file_paths, batch_size):\n",
    "    while True:\n",
    "        file_paths = shuffle(file_paths)\n",
    "        for i in range (0, len(file_paths), batch_size):\n",
    "            batch_files = file_paths[i:i + batch_size]\n",
    "            images, labels =[], []\n",
    "            for file in batch_files:\n",
    "                with rasterio.open(file) as src:\n",
    "                    image = src.read()\n",
    "                    image = np.moveaxis(image, 0, -1)\n",
    "                label = 1 if '/Damaged/' in file else 0\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "            yield np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43ebcbdc-a295-4535-80cf-b2931cf08439",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to get file paths\n",
    "def get_file_paths(base_path):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.tif'):\n",
    "                file_paths.append(os.path.join(root, file))\n",
    "    return file_paths\n",
    "\n",
    "# Get file paths\n",
    "train_files = get_file_paths(base_training_path)\n",
    "test_files = get_file_paths(base_testing_path)\n",
    "\n",
    "# Split training data for validation\n",
    "train_files, val_files = train_test_split(train_files, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4825be2c-195c-4465-af21-a2ecf23da0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights\n",
    "labels = [1 if '/Damaged/' in file else 0 for file in train_files]\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "batch_size = 32\n",
    "train_generator = custom_image_generator(train_files, batch_size)\n",
    "val_generator = custom_image_generator(val_files, batch_size)\n",
    "test_generator = custom_image_generator(test_files, batch_size)\n",
    "\n",
    "# Model architecture with Dropout and L2 regularization\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=l2(0.001))(x)  # L2 regularization\n",
    "x = Dropout(0.5)(x)  # Dropout\n",
    "output = Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001))(x)  # L2 regularization on output layer as well\n",
    "model = Model(inputs=base_model.input, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b534103e-543d-4c18-afaa-fbeb5d4789dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /Users/amartinh/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "2688/2688 [==============================] - 12450s 5s/step - loss: 4.1503 - accuracy: 0.7133 - precision: 0.4822 - recall: 0.6413 - f1_score: 0.5505 - val_loss: 1.6809 - val_accuracy: 0.8010 - val_precision: 0.6277 - val_recall: 0.6672 - val_f1_score: 0.6468\n",
      "Epoch 2/10\n",
      "2688/2688 [==============================] - 11629s 4s/step - loss: 1.5900 - accuracy: 0.7812 - precision: 0.5865 - recall: 0.6813 - f1_score: 0.6304 - val_loss: 1.5689 - val_accuracy: 0.8124 - val_precision: 0.6618 - val_recall: 0.6412 - val_f1_score: 0.6513\n",
      "Epoch 3/10\n",
      "2688/2688 [==============================] - 11778s 4s/step - loss: 1.2426 - accuracy: 0.8015 - precision: 0.6259 - recall: 0.6852 - f1_score: 0.6542 - val_loss: 1.1103 - val_accuracy: 0.7465 - val_precision: 0.5240 - val_recall: 0.7967 - val_f1_score: 0.6322\n",
      "Epoch 4/10\n",
      "2688/2688 [==============================] - 11560s 4s/step - loss: 1.0254 - accuracy: 0.8095 - precision: 0.6399 - recall: 0.6953 - f1_score: 0.6665 - val_loss: 0.9497 - val_accuracy: 0.7443 - val_precision: 0.5206 - val_recall: 0.8100 - val_f1_score: 0.6338\n",
      "Epoch 5/10\n",
      "2688/2688 [==============================] - 11415s 4s/step - loss: 0.8502 - accuracy: 0.8182 - precision: 0.6635 - recall: 0.6819 - f1_score: 0.6726 - val_loss: 0.7880 - val_accuracy: 0.8290 - val_precision: 0.7085 - val_recall: 0.6360 - val_f1_score: 0.6703\n",
      "Epoch 6/10\n",
      "2688/2688 [==============================] - 11576s 4s/step - loss: 0.7585 - accuracy: 0.8237 - precision: 0.6758 - recall: 0.6846 - f1_score: 0.6802 - val_loss: 0.7861 - val_accuracy: 0.8163 - val_precision: 0.6591 - val_recall: 0.6778 - val_f1_score: 0.6683\n",
      "Epoch 7/10\n",
      "2688/2688 [==============================] - 11531s 4s/step - loss: 0.7011 - accuracy: 0.8336 - precision: 0.7024 - recall: 0.6808 - f1_score: 0.6914 - val_loss: 0.7271 - val_accuracy: 0.8189 - val_precision: 0.6611 - val_recall: 0.6904 - val_f1_score: 0.6754\n",
      "Epoch 8/10\n",
      "2688/2688 [==============================] - 11566s 4s/step - loss: 0.6687 - accuracy: 0.8427 - precision: 0.7245 - recall: 0.6863 - f1_score: 0.7049 - val_loss: 0.7528 - val_accuracy: 0.8211 - val_precision: 0.6698 - val_recall: 0.6801 - val_f1_score: 0.6749\n",
      "Epoch 9/10\n",
      "2688/2688 [==============================] - 12024s 4s/step - loss: 0.6777 - accuracy: 0.8431 - precision: 0.7254 - recall: 0.6880 - f1_score: 0.7062 - val_loss: 0.7159 - val_accuracy: 0.8219 - val_precision: 0.6672 - val_recall: 0.6953 - val_f1_score: 0.6809\n",
      "Epoch 10/10\n",
      "2688/2688 [==============================] - 11673s 4s/step - loss: 0.6142 - accuracy: 0.8492 - precision: 0.7475 - recall: 0.6780 - f1_score: 0.7111 - val_loss: 0.7550 - val_accuracy: 0.7361 - val_precision: 0.5103 - val_recall: 0.8272 - val_f1_score: 0.6312\n",
      "141/331 [===========>..................] - ETA: 11:29 - loss: 0.7135 - accuracy: 0.7558 - precision: 0.5364 - recall: 0.8243 - f1_score: 0.6499"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amartinh/opt/anaconda3/lib/python3.8/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331/331 [==============================] - 1201s 4s/step - loss: 0.7435 - accuracy: 0.7462 - precision: 0.5236 - recall: 0.8219 - f1_score: 0.6397\n",
      "Test Accuracy: 0.7462235689163208\n",
      "Test Precision: 0.523590087890625\n",
      "Test Recall: 0.8219083547592163\n",
      "Test F1 Score: [0.6396783]\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', Precision(), Recall(), tfa.metrics.F1Score(num_classes=1, threshold=0.5)])\n",
    "\n",
    "# Callbacks for early stopping, model checkpointing, and logging\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "model_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True, monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "csv_logger = CSVLogger('training_log.csv', append=True)\n",
    "\n",
    "# Fit the model with callbacks\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=len(train_files) // batch_size,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=len(val_files) // batch_size,\n",
    "                    epochs=10,\n",
    "                    class_weight=class_weights_dict,\n",
    "                    callbacks=[model_checkpoint_callback, early_stopping_callback, csv_logger])\n",
    "\n",
    "# Save the model\n",
    "model.save('wildfiredetectionafterVGG16.keras')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy, test_precision, test_recall, test_f1_score = model.evaluate(test_generator, steps=len(test_files) // batch_size)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Test F1 Score: {test_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b920be7-e4bc-4be4-be01-398e8235762c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
