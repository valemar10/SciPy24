{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b254dd9-30a0-409b-9959-cb65e6908568",
   "metadata": {},
   "source": [
    "# Notebook to run a VGG16 model on the Labelled After Fire GeoTIFF Images\n",
    "\n",
    "#### Import necessary packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d11a0041-1539-4473-b57b-718bc64f661a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff28a6c-5cf6-481b-8e21-2dc2d738e847",
   "metadata": {},
   "source": [
    "#### Define a custom image generator for GeoTIFF files using rasterio to use on the VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae3e2bde-6e45-4507-b3a3-007a45814b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base paths for training and testing\n",
    "base_training_path =  '/Volumes/HD710PRO/Fire_and_Hurricane_Images/Fire/BinaryData/Training'\n",
    "base_testing_path =  '/Volumes/HD710PRO/Fire_and_Hurricane_Images/Fire/BinaryData/Test'\n",
    "\n",
    "# This image generator does not implement Keras preprocess_input because when using it the model was computationally expensive and it was obtaining low accuracies\n",
    "def custom_image_generator(file_paths, batch_size):\n",
    "    while True:\n",
    "        file_paths = shuffle(file_paths)\n",
    "\n",
    "        for i in range(0, len(file_paths), batch_size):\n",
    "            batch_files = file_paths[i:i + batch_size]\n",
    "            images, labels = [], []\n",
    "\n",
    "            for file in batch_files:\n",
    "                with rasterio.open(file) as src:\n",
    "                    image = src.read()\n",
    "                    image = np.moveaxis(image, 0, -1)  # Channels last\n",
    "\n",
    "                label = 1 if '/Damaged/' in file else 0\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "\n",
    "            yield np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b4f326-b1e0-4fac-a8a3-67be6e2015b6",
   "metadata": {},
   "source": [
    "#### Compute the file paths and split the data into training, test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd6084f6-506b-44d3-a4fe-0e9475aa02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths(base_path):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.tif'):\n",
    "                file_paths.append(os.path.join(root, file))\n",
    "    return file_paths\n",
    "\n",
    "train_files = get_file_paths(base_training_path)\n",
    "test_files = get_file_paths(base_testing_path)\n",
    "\n",
    "# Split training data for validation\n",
    "train_files, val_files = train_test_split(train_files, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dffa4bc-3bfa-48b8-a539-73992a288b0f",
   "metadata": {},
   "source": [
    "#### Define batch size and generate the training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94a29c79-a261-439b-a1c8-04026a2ba572",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_generator = custom_image_generator(train_files, batch_size)\n",
    "val_generator = custom_image_generator(val_files, batch_size)\n",
    "test_generator = custom_image_generator(test_files, batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d3e1ab-fabb-47d4-bf72-b44ac0b00076",
   "metadata": {},
   "source": [
    "#### Define and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77bb7385-13d2-4acc-835b-98540d0e520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', Precision(), Recall(), tfa.metrics.F1Score(num_classes=1, threshold=0.5)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99d252a-c797-4a7b-aa57-db9c25bf006e",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0e0064d-dad9-42c9-8560-5634772a9296",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2688/2688 [==============================] - 42184s 16s/step - loss: 1.6159 - accuracy: 0.7951 - precision_2: 0.6889 - recall_2: 0.4587 - f1_score: 0.5507 - val_loss: 0.4836 - val_accuracy: 0.8216 - val_precision_2: 0.7688 - val_recall_2: 0.4973 - val_f1_score: 0.6040\n",
      "Epoch 2/10\n",
      "2688/2688 [==============================] - 41087s 15s/step - loss: 0.4201 - accuracy: 0.8491 - precision_2: 0.8119 - recall_2: 0.5843 - f1_score: 0.6796 - val_loss: 0.4942 - val_accuracy: 0.8318 - val_precision_2: 0.7499 - val_recall_2: 0.5754 - val_f1_score: 0.6511\n",
      "Epoch 3/10\n",
      "2688/2688 [==============================] - 40506s 15s/step - loss: 0.3562 - accuracy: 0.8754 - precision_2: 0.8514 - recall_2: 0.6601 - f1_score: 0.7437 - val_loss: 0.5986 - val_accuracy: 0.8380 - val_precision_2: 0.8034 - val_recall_2: 0.5404 - val_f1_score: 0.6462\n",
      "Epoch 4/10\n",
      "2688/2688 [==============================] - 39089s 15s/step - loss: 0.2835 - accuracy: 0.8983 - precision_2: 0.8886 - recall_2: 0.7191 - f1_score: 0.7949 - val_loss: 0.5470 - val_accuracy: 0.8281 - val_precision_2: 0.7222 - val_recall_2: 0.6024 - val_f1_score: 0.6569\n",
      "Epoch 5/10\n",
      "2688/2688 [==============================] - 42467s 16s/step - loss: 0.2348 - accuracy: 0.9180 - precision_2: 0.9207 - recall_2: 0.7667 - f1_score: 0.8367 - val_loss: 0.7033 - val_accuracy: 0.8326 - val_precision_2: 0.7597 - val_recall_2: 0.5647 - val_f1_score: 0.6478\n",
      "Epoch 6/10\n",
      "2688/2688 [==============================] - 42031s 16s/step - loss: 0.1937 - accuracy: 0.9322 - precision_2: 0.9421 - recall_2: 0.8017 - f1_score: 0.8663 - val_loss: 0.9004 - val_accuracy: 0.8196 - val_precision_2: 0.7014 - val_recall_2: 0.5948 - val_f1_score: 0.6437\n",
      "Epoch 7/10\n",
      "2688/2688 [==============================] - 48556s 18s/step - loss: 0.1642 - accuracy: 0.9426 - precision_2: 0.9544 - recall_2: 0.8301 - f1_score: 0.8879 - val_loss: 0.8241 - val_accuracy: 0.8255 - val_precision_2: 0.7289 - val_recall_2: 0.5726 - val_f1_score: 0.6414\n",
      "Epoch 8/10\n",
      "2688/2688 [==============================] - 49512s 18s/step - loss: 0.1386 - accuracy: 0.9493 - precision_2: 0.9643 - recall_2: 0.8462 - f1_score: 0.9014 - val_loss: 0.9788 - val_accuracy: 0.8236 - val_precision_2: 0.7104 - val_recall_2: 0.5946 - val_f1_score: 0.6474\n",
      "Epoch 9/10\n",
      "2688/2688 [==============================] - 41573s 15s/step - loss: 0.1217 - accuracy: 0.9553 - precision_2: 0.9749 - recall_2: 0.8589 - f1_score: 0.9132 - val_loss: 1.0623 - val_accuracy: 0.8281 - val_precision_2: 0.7580 - val_recall_2: 0.5464 - val_f1_score: 0.6350\n",
      "Epoch 10/10\n",
      "2688/2688 [==============================] - 40475s 15s/step - loss: 0.1374 - accuracy: 0.9565 - precision_2: 0.9757 - recall_2: 0.8626 - f1_score: 0.9157 - val_loss: 1.2363 - val_accuracy: 0.8331 - val_precision_2: 0.7522 - val_recall_2: 0.5835 - val_f1_score: 0.6572\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_files) // batch_size,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_files) // batch_size,\n",
    "    epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb76a5d-ed3b-462b-bbfc-fe95007e1320",
   "metadata": {},
   "source": [
    "### Save and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cbe36dc-e8a6-4a09-a952-9c7493d8a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('wildfiredetectionafterVGG16.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdd84b51-d019-4202-8574-3978587cb9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "903d4748-f01d-4bf8-b69a-b8775ff0bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('wildfiredetectionafterVGG16.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22323ef3-4b87-4970-b698-fc40099f7e55",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/331 [=========================>....] - ETA: 14:00 - loss: 1.2443 - accuracy: 0.8317 - precision_2: 0.7516 - recall_2: 0.5889 - f1_score: 0.6604"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331/331 [==============================] - 6570s 20s/step - loss: 1.2207 - accuracy: 0.8327 - precision_2: 0.7499 - recall_2: 0.5890 - f1_score: 0.6598\n",
      "Test Accuracy: 0.8326565027236938\n",
      "Test Precision: 0.7498908638954163\n",
      "Test Recall: 0.5889612436294556\n",
      "Test F1 Score: [0.65975416]\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy, test_precision, test_recall, test_f1_score = model.evaluate(\n",
    "    test_generator,\n",
    "    steps=len(test_files) // batch_size)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"Test F1 Score: {test_f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688bcb4-33b2-4145-8298-e1d800ca0bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
